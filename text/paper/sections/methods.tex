% !TEX root = ../eval.tex

\section{Methods}%
\label{sec:data}

While we were unable to pre-register the analysis because we have had access to
and been working with the Money Dashoard data for months, we proceeded in the
same spirit: we first wrote a draft of the paper in the form of a pre-analysis
plan, following \citet{olken2015promises}, then tested the entire code base --
data pre-processing, balance checks, main analysis, and extensions -- with a 1
percent sample, and finally ran the entire analysis.


\subsection{Dataset}%
\label{sub:dataset}

Limitations:
\begin{itemize}
    \item We have more data for users that signed up later. So average user in
        the study is not the average MDB user. If time of signup is mainly
        driven by financial savyness, then study sample is closer to overall
        population than MDB sample (if we rank groups as early joiners > late
        joiners > never joiners in terms of financial sophistication). If,
        however, signup reflects something like openness to newness, then it's
        not necessarily correlated with financial savyness. Either way, we
        might ignore it for now. We could test whether behaviour differs
        between early or late adopters, but that doesn't seem important enough.
\end{itemize}


\subsection{Sample selection}%
\label{sub:sample_selection}

To assess the impact of app use on users' financial behaviour we need to
observe their relevant financial history for a sufficiently long period of time
prior to and after signup. For our purpose here, ``relevant
financial history'' includes the complete set of spending transactions and all
savings account inflows and outflows, and ``sufficiently long period'' is a
period of 6 months prior to and after signup, with the month of signup being
the first month of the latter period.\footnote{In
Appendix~\ref{sub:alternative_matching_method} we show results with different
window lengths. \edit{The results are unchanged.}}

Table~\ref{tab:selection} provides an overview of the precise conditions we applied to implement
these criteria and their effect on the sample size. The set of functions that
implement each condition can be found on \href{path-to-github}{path to github}.

\begin{table}
\centering
\caption{Sample selection}\label{tab:selection}
\input{\tabdir/sample_selection_XX1.tex}
\tabnote{\textwidth}{Number of users, user-months, transactions, and
transaction volume in millions of British Pounds left in our sample after each sample selection step. Link to sample selection
code:
\href{https://github.com/fabiangunzinger/mdb_eval/blob/main/src/data/selectors.py}{\faGithub}.}
\end{table}


\subsection{Treatment}%
\label{sub:treatment}

A user changes treatment status from untreated to treated when they start using
the app. Figure~\ref{fig:treatplot_sample_raw} shows the treatment history for
200 randomly selected users.

\begin{figure}[htpb]
    \centering
    \caption{Treatment assignment plot}%
    \includegraphics[width=0.8\linewidth]{\figdir/treatplot_sample_raw.png}
    \label{fig:treatplot_sample_raw}

    \fignote{\textwidth}{Each horizontal line shows for one of 200 randomly
        selected users the observed pre and post signup periods in blue and
        red, respectively. The faint vertical white lines indicate month
        borders, whitespace indicates periods in which we do not observe the
    user. To the left of the observed period, this is because the app cannot
access data before that point when the user signs up; to the right, because
they have stopped using the app.}

\end{figure}


\subsection{Outcomes}%
\label{sub:outcomes}

\begin{table}[htpb]
    \centering\footnotesize
    \caption{Outcome description}
    \label{tab:label}
    \begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}X
        >{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}X}
    \hline\hline
    Outcome (name in dataset) & Definition  & Rationale \\
    \hline\\
    \multicolumn{3}{c}{Primary outcome}\\\\

    Net savings (\textit{sa\_netflows\_norm})&
    Inflows into minus outflows out of all of a user's savings accounts divided
    by monthly income. To capture only ``user-generated'' flows, we exclude
    interest and ``save the change'' transactions, as well as transactions of
    less than \pounds5 in absolute
    value. Monthly income and raw inflows and outflows are winsorised at the 1
    percent level.\href{https://github.com/fabiangunzinger/mdb_eval/blob/d094f8cd364f64bbe3d4e644abbff726af86de2f/src/data/aggregators.py\#L27}{\faGithub}&
    We focus on net inflows to capture effective savings.\\\\

    \multicolumn{3}{c}{Secondary outcomes}\\\\

    Positive net savings dummy (\textit{has\_pos\_sa\_netflows})&
    Dummy equal to 1 if there were positive net savings (as defined above).&
    Captures extensive margin of savings (change in number of deposits).\\

    Positive net savings (\textit{pos\_sa\_netflows})&
    Equal to net savings if there were positive net savings.&
    Captures intensive margin of savings (change in deposit amount).\\

    ...add from text below&&\\

    \hline\hline
    \end{tabularx}
\end{table}

For a more nuanced understanding of how app use affects savings we also
consider net-savings -- total savings account inflows minus outflows -- as a
proportion of monthly income to see whether a willingness to save more might be
offset by a (later) need to withdraw funds, and a dummy variable for whether a
user has any savings account inflows in a given month to see whether the app
helps users save at all. To investigate possible channels, we consider total
spend, highly discretionary spend, banking charges, the total amount of
borrowing, as well as payday borrowing, all as proportion of monthly income.

\paragraph{Adjusting for multiple hypothesis tests}%
\label{par:adjusting_for_multiple_hypothesis_tests}
We think of our secondary outcomes as exploratory and do not make any
adjustments for multiple hypothesis testing.\footnote{For a recent
game-theoretically motivated discussion of when and how to correct for multiple
hypothesis testing, see \citet{viviano2021should}.} An alternative approach,
based on \citet{anderson2008multiple}, would be to group outcomes into
``savings'', ``spending'', ``borrowing'', and ``fees'', and consider them as
different dimensions of a latent variable of interest which we might call
``financial management skills''. We do not do that for two reasons: first and
foremost, because we think it is natural to think of the amount saved as the
ultimate outcome and of other outcomes as providing a more nuanced
understanding of savings behaviour or as suggesting possible channels through
which app use affects savings. Thinking of savings as the main goal is also
reflected in Money Dashboard's main promise, which is to help users spend less
and save more, as shown in Figure~\ref{fig:mdb_website}. Second, as pointed out
in \citet{carlin2017fintech}, incurring overdraft fees is not an unambiguous
sign of a financial mistake, as the opportunity to go into overdraft confers a
benefit to the consumer.\footnote{For further discussions on fees, see
\citet{jorring2020financial, stango2009consumers}.}


\subsection{Covariates}%
\label{sub:covariates}

\begin{itemize}
    \item Motivation to save more (change in savings prior to app use? opening
        of savings account)
\end{itemize}


\subsection{Difference-in-difference}%
\label{sub:difference_in_difference}

Control group design:
\begin{itemize}

    \item We only have data for a self-selected group of people who choose to
        use Money Dashboard. This has a couple consequences:

        \begin{itemize}

            \item By virtue of signing up to an app that helps them manage
                their money, these users are different from those who don't
                sign up. As a result, we are unable to answer the question of
                whether use of Money Dashboard helps the average person in the
                population as a whole save more.\footnote{One way to get closer
                    to that answer is to re-weight our sample on observable
                    demographic variables so as to match the UK population as a
                    whole. But our sample differs from the population as a
                    whole both is ways that are observable (demographic
                    variables) and unobservable (self-awareness that they need
                    help managing their money, cognitive resources to engage
                    with the app, motivation to do so). Re-weighting would only
                    help us deal with the first of these.} Instead, we are
                    answering the question whether Money Dashboard succeeds in
                    helping its \textit{users} save more.

                \item Something precipitated users to sign up at a particular
                    point in time but not before. To the extent that the
                    decision to sign up is linked to a desire to save more,
                    ``desire to save more'' is a confounding effect we cannot
                    directly control for. We try to address this so some extent
                    by trying to control for signs of motivation for savings
                    (e.g. starting to save more even before app use)
        \end{itemize}

    \item Money Dashboard can access up to three years of historic data for
        each account a user links to their account.

    \item Each user for whom we have sufficient data thus serves as both a
        treatment unit and a potential control unit.

    \item We use a difference-in-differences design to estimate the effect of
        app use. Because we do not have a separate control group, we use the
        per-signup data of Money Dashboard users as control periods and use
        matching to find comparable control user for each tretment user.

    \item To do this, we use the matching estimator for panel data proposed by
        \citet{imai2021matching}. Following paper, we conduct the following
        steps:

    \item For each treated observation, we find a set of control observations
        with that share the same treatment history for a period of $L$ periods
        before the treatment and $F$ periods after the treatment. In our
        baseline specification, we rely on a year's worth of data around the
        treatment period and set $L=6$ and $F = 0, 1, 2, 3, 4, 5$.

    \item Identification assumption is that potential outcomes only depend on
        treatment status of the past L periods. In general, this means that if
        treatment has a cumulative effect over time, the full effect is reached
        after L periods. In our context, this means that any effect on savings
        behaviour from usign the app is fully realised after L periods. (I
        think this means that if we look at the treatment effect for F periods
        forward, the effect should not become stronger after F = L).

    \item tbc once implemented.

    \item Selection of covariates: all variables that simultaneously affect
        treatment and outcomes. No need to control for fixed effects: these
        capture unobserved time-invariant factors that make an individual sign
        up to MDB and affect its spending habits. Given that these are time
        invariant, and that all users eventually sign up, there is no
        difference between control and treatment units in these factors. Month
        of year: should probably include, as can affect p of signup and
        spending behaviour.

\end{itemize}

DiD identification assumptions:
\begin{itemize}
    \item No spillover effects: the potential outcome of unit $i$ at time $t$
        is independent of the treatment status of other units. This is violated
        if a user's partner or friends also use the app and, through sharing
        their experiences or motivations, influence the user's savings
        behaviour.

    \item Carryover effects no longer than $L$ periods: a user's potential
        outcome in period $t$ is independent of treatment status in periods
        more than $L$ periods ago. Given that we are dealing with an absorbing
        treatment, this is not a very strong assumption in our context, and we
        choose $L$ based on what we think is an informative number of periods
        to observe pre-app use behaviour.\footnote{An absorbing treatment is
            one that cannot be reversed, and hence we only change from
            untreated to treated once.}.

    \item Parallel trends: the spending trajectory between treated and control
        units would have continued to be parallel if the treated unit hadn't
        started using the app. This is violated whenever an intended change in
        savings behaviour also provided the impetus for the user to start using
        the app, which is likely to occurr frequently. To the extent this is
        the case, we have an ommitted variable ``motivation to save more'',
        which both changes the user's savings behaviour and their treatment
        status. Because of this, what we are measuring is not a pure ATT of app
        use -- the effect of app use on savings over and above the change
        precipitated by a change motivation -- but the effect of app use for
        users motivated to save more.

\end{itemize}


\begin{figure}[htpb]
    \centering
    \caption{Match set examples}%
    \includegraphics[width=\linewidth]{\figdir/matchset_examples.png}
    \label{fig:matchset_examples}

    \fignote{\textwidth}{}

\end{figure}


\begin{figure}[htpb]
    \centering
    \caption{Distribution of size of matched control units}%
    \includegraphics[width=0.8\linewidth]{\figdir/hist_matchset_size.png}
    \label{fig:hist_matchset_size}

    \fignote{\textwidth}{In the first step of the matching proceedure, each
        user gets assigned a set of potential control users that share the same
        treatment history for a specified number of periods before the user
        signs up to teh app (6 months, in our baseline specification), but that
        do not sign up themselves for a specified number of periods after the
        treatment user has signed up (another 6 months, in our baseline
        specification). The figure shows the distribution of the sizes of these
        sets of potential control users. The pink vertical bar on the left
    shows to count of users for whom no control users cound be found.}

\end{figure}

\begin{figure}[htpb]
    \centering
    \caption{Covariance balance}%
    \includegraphics[width=0.8\linewidth]{\figdir/covar_balance.png}
    \label{fig:covar_balance}

    \fignote{\textwidth}{Average covariate standard deviation between treatment and
        control units for each pre-treatment period using the entire set of
        potential controls on the left and, on the right, the refined set of
        controls, which, in our baseline specification, consists of the nearest
        neighbour match based on the propensity score.}

\end{figure}

\begin{figure}[htpb]
    \centering
    \caption{Matching estimates}%
    \includegraphics[width=0.8\linewidth]{\figdir/match_estimates.png}
    \label{fig:match_estimates}

    \fignote{\textwidth}{}

\end{figure}

Is estimate causal?
\begin{itemize}
    \item \citet{king2006dangers} show that there are four sources of bias
        (ommitted variable, posttreatment, interpolation, extrapolation).
    
    \item Discuss each in turn to argue that effect is causal (for our population
        of interest, which are people signing up to MDB). 
\end{itemize}

\subsection{Code access}%
\label{sub:code_access}

We provide links to code that creates key elements of the paper such as
variable definitions and sample selection directly in the relevant places in
the paper so they can be accessed conveniently. The links are indicated with
the GitHub logo, \faGithub. The hope is that this helps the
curious reader clarify questions about subtleties they might have while reading
the paper. The complete projects GitHub repo is at
\href{https://github.com/fabiangunzinger/mdb\_eval}{https://github.com/fabiangunzinger/mdb\_eval}.


