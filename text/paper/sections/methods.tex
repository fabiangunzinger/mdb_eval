% !TEX root = ../eval.tex

\section{Methods}%
\label{sec:data}

\subsection{Data}%
\label{sub:data}

\paragraph{Dataset description:}%
\label{par:dataset_description}

I use data from a UK-based financial management app that allows users to link
accounts from different banks to obtain an integrated view of their finances.
The complete dataset contains more than 500 million transactions made between
2012 and June 2020 by about 250,000 users, and provides information such as
date, amount, and description about the transaction as well as account and
user-level information. Crucially for this paper, the app can access up to
three years of historic data for each linked account.

The main advantage of the data for the study of consumer financial behaviour is
that we can observe user behaviour at the transaction level across all their
accounts, and that the data is automatically collected rather than collected
through a survey.

The main limitation is the non-representativeness of the sample relative to the
population as a whole. Financial management apps are known to be used
disproportionally by men, younger people, and people of higher socioeconomic
status \citep{carlin2019generational}. Also, as pointed out in
\citet{gelman2014harnessing}, a willingness to share financial information with
a third party might not only select on demographic characteristics, but also
for an increased need for financial management or a higher degree of financial
sophistication. Because our analysis does not rely on representativeness, we do
not address this.\footnote{For an example of how re-weighing can be used to
mitigate the non-representative issue, see \citet{bourquin2020effects}.}


\paragraph{Cleaning:}%
\label{par:cleaning}

I use the dataset described above for a number of projects, and perform a
number of steps to create a minimally cleaned version of the dataset that is
the basis for all such projects. These steps are performed in a dedicated
data repository and not run as part of this project, but the module with
all cleaning functions is available in the project directory.\footnote{Link to
    cleaning functions:
\href{https:/egithub.com/fabiangunzinger/mdb_eval/blob/f51e49c95c5884d2dc417be23921a8acd85aec9d/src/data/clean.py}{\faGithub}}

Here, I briefly describe the main cleaning steps and their rationale. I drop
all transactions with a missing description string because these cannot be
categoriesed, and all transactions that are not automatically categoriesed by
the app. Dropping these transactions makes is likely that we will underestimate
amounts spent and saved, but minimises the risk of incorrectly classified
transactions. I group transactions into transaction, spend, and income
subgroups. Spend subgroups are defined following \citet{muggleton2020evidence};
income subgroups, following \citet{hacioglu2020distributional}.\footnote{Link
to classification file:
\href{https://github.com/fabiangunzinger/mdb_eval/blob/92af366d4c4052cc7a7f78a6178086de8ecdfb75/src/data/txn_classifications.py}{\faGithub}}
Finally, I classify as duplicates and drop transactions with identical user ID,
account ID, date, amount, and transaction description. This will drop some
genuine transactions, such as a user buying two identical cups of coffees at
the same coffee shop on the same day. However, data inspection suggests that in
most cases, we remove genuine duplicates.


\paragraph{Sample selection}%
\label{par:sample_selection}

We select our sample so as to include users for whom we can be reasonably
certain that we observe all relevant financial transactions, and do so for at
least six months before and after they sign up to the app. In addition to that,
we exclude users who might use the app for business purposes as well as
pensioneers, whose financial objectives might be different.

\begin{table}
\centering
\caption{Sample selection}\label{tab:selection}
\input{\tabdir/sample_selection.tex}
\tabnote{\textwidth}{Number of users, user-months, transactions, and
transaction volume in millions of British Pounds left in our sample after each sample selection step. Link to sample selection
code:
\href{https://github.com/fabiangunzinger/mdb_eval/blob/main/src/data/selectors.py}{\faGithub}.}
\end{table}


Table~\ref{tab:selection} lists the precise conditions we applied to implement
these criteria and their effect on sample size. We remove the first and last
month of data for all users because we are unlikely to observe all transactions
for these months. We also drop test users, since their objectives for app use
might have been different from ordinary users.\footnote{We cannot identify test
users precisely, but drop users who signed up prior to or during the first year
the app was in operation.}

To ensure that we observe users for at least 12 months around app signup, we
require 6 months of data before the signup month, and another five months after
the signup month. Our main outcome variable is netflows into a user's savings
accounts. It is thus critical that we observe enough historical data for these
savings accounts to ensure that we observe all transactions during our 12 month
perdiod of interest. This is complicated by the fact that we cannot see when an
account was opened at the bank, but only when it was added to the app. While
cases where a user adds an account to the app as soon as it was opened are
unproblematic, users will often add accounts after they were opened, either
because they have accounts that they opened before signing up to the app, or
because they opened new accounts after signup but add them to the app with a
delay. In such cases, it is critical that, once the account is added, we
observe the complete historical data up to 6 months before signup or up to the
month in which the account was opened, whichever happened later. To see why
this is critical, imagine a scenario where a user opens an account 10 months
before they sign up to the app, makes a monthly transfter to the account of
\pounds100, adds the account to the app on signup, but we onserve only 3 months
of historical data. In this case we would observe that the user saved
\pounds300 before signup and \pounds600 after, and erroneously conclude that
post signup savings were twice as high. The most extreme case we need to cover
is that of a user opening a savings account more than six months before signup
and adding the account to the app five months after signup, in which case we
need to be sure to observe 12 months of historical data. As shown in
Appendix~\ref{app:data}, all major banks started providing 12 months of
historical data for current and savings accounts from April 2017 onwards, which
is why we restrict our sample to users who signed up in or after that month.

To ensure that we can be reasonably certain to observe users have added all
their financial accounts to the app, we restrict our sample to users with at
least one savings and current account, with an annual income of at least
\pounds5,000, and a minimum of 10 transactions and a spend of \pounds200 every
month. To remove users who might use the app for business purposes, we drop
users with more than 10 active accounts in any given month. Finally, we remove
users for whom we cannot observe all demographic information we use as
covariates in our analysis, and users who are not between the ages of 18 and
65, as their financial objectives are plausibly different.


\paragraph{Data transformations:}%
\label{par:data_transformations}

To minimise the influence of outliers, we winsorise spend, income, and savings
accounts flow variables at the 1 percent level or -- if we winsorise on both
ends of the distribution -- at the 0.5 percent level.


\paragraph{Summary statistics}%
\label{par:summary_statistics}

Figure~\ref{fig:sample_description} describes the sample.

\begin{figure}[H]
    \centering
    \caption{Sample characteristics}
    \includegraphics[width=\linewidth]{\figdir/sample_description.png}
    \label{fig:sample_description}
    \fignote{\textwidth}{Panels A and B show the distribution of disposable
        income and total spending in 2019, respectively, benchmarked against
        the 2018/19 wave of the ONS Living Cost and Food Survey (LCFS). The
        remaining panels show the data distributions of age, gender, region,
    and the number of active accounts.}%
\end{figure}

Table~\ref{tab:sumstats} provides summary statistics.

\input{\tabdir/sumstats.tex}

We use data from the 2018-2019 wave of the Office of National Statistics' Living Costs and Food
Survey (LCFS).\footnote{We accessed the data via the UK Data Service at the
following url:
\url{https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=8686}.}
Data covers the period between April 2018 and March 2019.


\subsection{Estimation}%
\label{sub:estimation}


\citet{callaway2021difference}.


SA setup:
\begin{itemize}
    \item Units that are treated in period 1 are dropped from the sample, since
        (i) there exists no possible control group based on which to identify
        their treatment effects and (ii) they are not useful as a control group
        themselves. (wp footnote 3)

    \item If there exists no never-treated units (as in our setup), then last
        treated group is dropped since there exists no valid "not-yet-treated"
        comparison group for them.

    \item This means that if we restrict our data to a balanced panel (e.g. all
        data from 2018 and 2019), the groups first treated in Jan 2018 and Dec
        2019 will be dropped from the sample.

    \item Assumption 3 allows for known treatment anticipation. In our case,
        with units self-selecting into treatment, it will be useful to do
        robustness checks for sensible anticipation levels. (In our case, the
        relevant anticipation period is time since deciding to save more/spend
        less and time when signing up to app. This could realistically be up to
        6 months). As CS point out in remark 1, increading delta makes
        the parallel trends assumption more restrictive, since it now needs to
        hold also for delta pre-treatment periods.
        Our results here are weird, though: if we think that during
        anticipation period peope already spend less, then this would bias
        baseline results downwards. Instead, we see the opposite. In the case
        with delta > 0, this also means we can identify GT effects only up to
        time where last cohort effectively starts its treatment (max g -
        delta), and, as discussed before, we cannot estimate GT for that last
        group, either.

    \item Conditional parallel trends are important in contexts when (i) there
        are covariate specific trends in outcome paths and (ii) the
        distribution of covariates differs between groups. (E.g. people who
        sign up to job training differ from those who don't and job outcomes
        depend on these covariates). In my context, do covariates differ
        between those who sign up and those who don't? (can investigate - month
        income, num accounts, total spend, etc. pre and post signup), and does
        savings path depend on these variables (we'd certainly think so).

        Actually, for my here, cov distr between treatment and control differs
        only if early users are different from later ones.

    \item Assumption 5 restricts pre-treatment trends (see discussion there and
        discuss in footnote).

\end{itemize}


Assumptions:
\begin{itemize}
    \item A1: Absorbing treatment. This is unproblematic.

    \item A2: Random sampling (each unit is independently drawn from a larger
        population of interest). This is not self-evidently true. In a narrow
        sense, MDB users are different by virtue of having signed up. One way
        to think of a super population is to think about knowing of MDB's
        existence to some extent as random, in which case the super population
        consists of all people who would have signed up if they had heard of
        MDB. Another is for signup to be partially driven by need, and need to
        be partially random. The super population is than everyone with a
        potential need in the future.

    \item A3: Limited (known) treatment anticipation. In baseline, we assume
        that there is no anticipation. We provide robustness checks with
        different anticipation periods.

    \item A5: Unconditional parallel trends based on not-yet treated groups.

    \item A6: Overlap condition: positive fraction of population starts
        treatment in each period, and propensity scores are bounded away from 1
        for all groups and times.

    \item We aggregate GT effects using a panel balanced in event times, with
        all units being greated for at least 5 periods. This avoids that the
        event study parameters are influenced by compositional issues (SA show
        in section 3.1.1 that without this restriction, aggregated treatment
        effects also are affected by different composition of groups and
        different group weights). This comes at the cost of fewer groups used
        for calculations. And in appendix we compare the results without this
        restriction.
\end{itemize} 

Allows for: Heterogeneous treatment across time and units


\subsection{Variables}%
\label{sub:variables}



\paragraph{Treatment}%
\label{par:treatment}

A user changes treatment status from untreated to treated when they start using
the app. Figure~\ref{fig:treatplot_sample_raw} shows the treatment history for
200 randomly selected users.

\begin{figure}[H]
    \centering
    \caption{Treatment assignment plot}%
    \includegraphics[width=0.8\linewidth]{\figdir/treatplot_sample_raw.png}
    \label{fig:treatplot_sample_raw}

    \fignote{\textwidth}{Each horizontal line shows the observed pre and post
        signup periods in blue and red, respectively, for one of 200 randomly
        selected users. The faint vertical white lines indicate month borders,
        whitespace indicates periods in which we do not observe the user. To
    the left of the observed period, this is because the app cannot access data
before that point when the user signs up; to the right, because they have
stopped using the app.}

\end{figure}


\paragraph{Outcomes}%
\label{par:outcomes}

Savings... see Table~\ref{tab:vars} for details.

For a more nuanced understanding of how app use affects savings we also
consider net-savings -- total savings account inflows minus outflows -- as a
proportion of monthly income to see whether a willingness to save more might be
offset by a (later) need to withdraw funds, and a dummy variable for whether a
user has any savings account inflows in a given month to see whether the app
helps users save at all. To investigate possible channels, we consider total
spend, highly discretionary spend, banking charges, the total amount of
borrowing, as well as payday borrowing, all as proportion of monthly income.



Net savings (\textit{netflows\_norm})
Inflows into minus outflows out of all of a user's savings accounts divided
by monthly income. To capture only ``user-generated'' flows, we exclude
interest and ``save the change'' transactions, as well as transactions of
less than \pounds5 in absolute
value. Monthly income and raw inflows and outflows are winsorised at the 1
percent level.
We focus on net inflows to capture effective savings.

Positive net savings dummy (\textit{has\_pos\_netflows})
Dummy equal to 1 if there were positive net savings (as defined above).
Captures extensive margin of savings (change in number of months with positive
net deposits)

Positive net savings (\textit{pos\_netflows})
Equal to net savings if there were positive net savings.
Captures intensive margin of savings (change in deposit amount in months with
positive net deposits)

\begin{figure}[H]
    \centering
    \caption{Savings patterns}%
    \includegraphics[width=\linewidth]{\figdir/savings_patterns.png}
    \label{fig:\figdir/savings_patterns}
    \fignote{\textwidth}{Panel A shows distribution of savings account inflow
        amounts, making clear that most transactions are the kinds of round
        amounts we would expect savings transactions to be. The data is
        truncated at \pounds1000. Panel B hows inflows, outflows, and netflows
        into savings accounts for six months before and five months after app
    use.}

\end{figure}


% \paragraph{Adjusting for multiple hypothesis tests}%
% \label{par:adjusting_for_multiple_hypothesis_tests}
% We think of our secondary outcomes as exploratory and do not make any
% adjustments for multiple hypothesis testing.\footnote{For a recent
% game-theoretically motivated discussion of when and how to correct for multiple
% hypothesis testing, see \citet{viviano2021should}.} An alternative approach,
% based on \citet{anderson2008multiple}, would be to group outcomes into
% ``savings'', ``spending'', ``borrowing'', and ``fees'', and consider them as
% different dimensions of a latent variable of interest which we might call
% ``financial management skills''. We do not do that for two reasons: first and
% foremost, because we think it is natural to think of the amount saved as the
% ultimate outcome and of other outcomes as providing a more nuanced
% understanding of savings behaviour or as suggesting possible channels through
% which app use affects savings. Thinking of savings as the main goal is also
% reflected in Money Dashboard's main promise, which is to help users spend less
% and save more, as shown in Figure~\ref{fig:mdb_website}. Second, as pointed out
% in \citet{carlin2017fintech}, incurring overdraft fees is not an unambiguous
% sign of a financial mistake, as the opportunity to go into overdraft confers a
% benefit to the consumer.\footnote{For further discussions on fees, see
% \citet{jorring2020financial, stango2009consumers}.}


\paragraph{Covariates}%
\label{par:covariates}

We control for baseline behaviour, events, and personal characteristics that,
to various degrees, capture a person's need, capacity, motivation, and
awareness to save. Table~\ref{tab:vars} lists all covariates used
together with their definition and the rationale for including them. For all
variables, we include contemporaneous values as well as lags for up to 6
periods. In addition, we control for the previous six months of savings to
capture time-invariant unobserved drivers of savings behaviour (in
specifications without fixed effects) as well as a possible signal for a higher
or lower need for future savings.

Following \citet{vanderweele2019principles} we include covariates that affect
either outcomes or the propensity for treatment or both, exclude from this
set of variables those that are instruments (affect the outcome only through their effect on
treatment propensity) and add to it proxies for unobserved variables that are a
common cause of both outcomes and treatment propensity.\footnote{
\citet{vanderweele2019principles} calls this the ``modified disjunctive cause
criterion'' for covariate selection, as it includes the set of variables that are causally
related to either outcomes, or treatment propensity, or both, but modified to
account for potential bias by excluding instruments and including proxies of
unobserved causes of both outcomes and treatment.}

The table below describes the construction and rationale for including of all
variables used. The code used to construct the variables is available on
\href{https://github.com/fabiangunzinger/mdb_eval/blob/d094f8cd364f64bbe3d4e644abbff726af86de2f/src/data/aggregators.py}{GitHub}.

\input{sections/covar_table.tex}


\subsection{Code access}%
\label{sub:code_access}

We provide links to code that creates key elements of the paper such as
variable definitions and sample selection directly in the relevant places in
the paper so they can be accessed conveniently. The links are indicated with
the GitHub logo, \faGithub. The hope is that this helps the
curious reader clarify questions about subtleties they might have while reading
the paper. The complete projects GitHub repo is at
\href{https://github.com/fabiangunzinger/mdb\_eval}{https://github.com/fabiangunzinger/mdb\_eval}.


